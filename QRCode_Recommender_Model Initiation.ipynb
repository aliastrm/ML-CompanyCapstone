{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Model initiation for recommendation feature\n",
        "This is the initiation model for the recommendation system to try the recommendation model using TFRS before being implemented into the company's capstone project.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OtOOdOkG1t4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installling the TensorFlow Recommenders"
      ],
      "metadata": {
        "id": "_OJ_Ck8-KBoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAzkUHpYJVa7"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "_OnBJG9qKIkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from typing import Dict, Text"
      ],
      "metadata": {
        "id": "ScGkHnI2JuuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading the data"
      ],
      "metadata": {
        "id": "Kgm2DBlcKNIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings data.\n",
        "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
        "\n",
        "# Select the basic features.\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"]\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tdAqKC0KPpM",
        "outputId": "56cde2fa-93d1-4b54-a19e-50d448190ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.\n",
            "WARNING:absl:`TensorInfo.dtype` is deprecated. Please change your code to use NumPy with the field `TensorInfo.np_dtype` or use TensorFlow with the field `TensorInfo.tf_dtype`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build vocabularies to convert user ids and movie titles into integer indices for embedding layers:"
      ],
      "metadata": {
        "id": "gWnjbw8CKlwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "user_ids_vocabulary.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
        "\n",
        "movie_titles_vocabulary = tf.keras.layers.StringLookup(mask_token=None)\n",
        "movie_titles_vocabulary.adapt(movies)"
      ],
      "metadata": {
        "id": "LEZ32kFmKj8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define a model\n"
      ],
      "metadata": {
        "id": "HdJolSiFLGMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensModel(tfrs.Model):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      user_model: tf.keras.Model,\n",
        "      movie_model: tf.keras.Model,\n",
        "      task: tfrs.tasks.Retrieval):\n",
        "    super().__init__()\n",
        "\n",
        "    # Set up user and movie representations.\n",
        "    self.user_model = user_model\n",
        "    self.movie_model = movie_model\n",
        "\n",
        "    # Set up a retrieval task.\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    # Define how the loss is computed.\n",
        "\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
        "\n",
        "    return self.task(user_embeddings, movie_embeddings)"
      ],
      "metadata": {
        "id": "pqpbpdJ2LI3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the two Models and the retrieval task"
      ],
      "metadata": {
        "id": "6fusUg7YhrjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define user and movie models.\n",
        "user_model = tf.keras.Sequential([\n",
        "    user_ids_vocabulary,\n",
        "    tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(), 64)\n",
        "])\n",
        "movie_model = tf.keras.Sequential([\n",
        "    movie_titles_vocabulary,\n",
        "    tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(), 64)\n",
        "])\n",
        "\n",
        "# Define your objectives.\n",
        "task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
        "    movies.batch(128).map(movie_model)\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVF5EgNQhwl_",
        "outputId": "c0a690ed-6af0-4c30-86e9-3834e0e762e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n",
            "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit, train and generate predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "lcNLKq7thzNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovieLensModel(user_model,movie_model,task)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
        "\n",
        "model.fit(ratings.batch(4096),epochs=3)\n",
        "\n",
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "index.index_from_dataset(\n",
        "    movies.batch(100).map(lambda title: (title, model.movie_model(title))))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEAJ0Y6yh77c",
        "outputId": "ba29d72a-5145-4990-a17b-d004362a63c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "25/25 [==============================] - 17s 541ms/step - factorized_top_k/top_1_categorical_accuracy: 8.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0017 - factorized_top_k/top_10_categorical_accuracy: 0.0051 - factorized_top_k/top_50_categorical_accuracy: 0.0441 - factorized_top_k/top_100_categorical_accuracy: 0.0999 - loss: 33093.0257 - regularization_loss: 0.0000e+00 - total_loss: 33093.0257\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 14s 556ms/step - factorized_top_k/top_1_categorical_accuracy: 1.6000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0048 - factorized_top_k/top_10_categorical_accuracy: 0.0141 - factorized_top_k/top_50_categorical_accuracy: 0.1049 - factorized_top_k/top_100_categorical_accuracy: 0.2109 - loss: 31015.4701 - regularization_loss: 0.0000e+00 - total_loss: 31015.4701\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 14s 552ms/step - factorized_top_k/top_1_categorical_accuracy: 3.6000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0078 - factorized_top_k/top_10_categorical_accuracy: 0.0215 - factorized_top_k/top_50_categorical_accuracy: 0.1444 - factorized_top_k/top_100_categorical_accuracy: 0.2683 - loss: 30418.6653 - regularization_loss: 0.0000e+00 - total_loss: 30418.6653\n",
            "Top 3 recommendations for user 42: [b'Rent-a-Kid (1995)' b'Just Cause (1995)' b'House Arrest (1996)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some recommendations.\n",
        "_, titles = index(np.array([\"39\"]))\n",
        "print(f\"Top 4 recommendations for user 39: {titles[0, :4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVZutq8CqnVE",
        "outputId": "41c48032-a99c-42e3-c039-8a54653c87c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 4 recommendations for user 39: [b'Spice World (1997)' b'Deconstructing Harry (1997)' b'Senseless (1998)'\n",
            " b'Blues Brothers 2000 (1998)']\n"
          ]
        }
      ]
    }
  ]
}